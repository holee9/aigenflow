"""
Gemini & Perplexity Reproducibility Test (Claude excluded due to auth issue).
"""

import asyncio
import hashlib
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright

PROFILE_DIR = Path.home() / ".aigenflow" / "profiles"
BROWSER_CHANNEL = "chrome"

# Test prompt
PROMPT = """AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸í° ê´€ë¦¬ ì‹œìŠ¤í…œì— ëŒ€í•œ ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ 2ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
ê° ì•„ì´ë””ì–´ëŠ” 1-2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""


def calculate_similarity(text1: str, text2: str) -> dict:
    """Calculate similarity between texts."""
    len1, len2 = len(text1), len(text2)
    len_sim = min(len1, len2) / max(len1, len2) if max(len1, len2) > 0 else 1.0

    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    jaccard = len(words1 & words2) / len(words1 | words2) if (words1 or words2) else 1.0

    sample_size = min(500, len(text1), len(text2))
    sample1, sample2 = text1[:sample_size], text2[:sample_size]
    char_match = sum(c1 == c2 for c1, c2 in zip(sample1, sample2)) / sample_size if sample_size > 0 else 1.0

    hash_match = 1.0 if hashlib.md5(text1.encode()).hexdigest() == hashlib.md5(text2.encode()).hexdigest() else 0.0

    return {
        "length_similarity": len_sim,
        "jaccard_similarity": jaccard,
        "character_match": char_match,
        "hash_match": hash_match,
        "overall": (len_sim * 0.2 + jaccard * 0.4 + char_match * 0.3 + hash_match * 0.1),
    }


async def test_gemini():
    """Test Gemini reproducibility (3 iterations)."""
    profile_path = PROFILE_DIR / "gemini"

    if not profile_path.exists():
        print("Gemini profile not found")
        return None

    responses = []
    errors = []

    print("\n" + "="*60)
    print("Testing GEMINI")
    print("="*60)

    async with async_playwright() as p:
        for i in range(3):
            context = await p.chromium.launch_persistent_context(
                str(profile_path),
                headless=False,
                channel=BROWSER_CHANNEL,
                viewport={"width": 1280, "height": 800},
                args=["--disable-blink-features=AutomationControlled"],
            )
            page = context.pages[0] if context.pages else await context.new_page()

            try:
                await page.goto("https://gemini.google.com", wait_until="domcontentloaded", timeout=30000)

                # Check login
                if "login" in page.url.lower():
                    print(f"  Message {i+1}/3: âœ— Not logged in")
                    await context.close()
                    return None

                print(f"  Message {i+1}/3...")

                # Wait for input
                await page.wait_for_selector(".ql-editor, textarea", timeout=15000)

                # Get the editor element
                editor = await page.query_selector(".ql-editor, textarea")
                if not editor:
                    errors.append(f"Message {i+1}: No editor found")
                    print(f"    âœ— No editor found")
                    await context.close()
                    continue

                # Type message
                await editor.fill(PROMPT)
                await asyncio.sleep(1)

                # Submit
                await editor.press("Enter")
                print("    sent, waiting...", end="", flush=True)

                # Wait for response
                await asyncio.sleep(20)

                # Capture response - try multiple selectors
                captured = False
                selectors = [
                    "div.model-response",
                    "markdown",
                    "div[data-test-id='chat-turn']",
                ]

                for selector in selectors:
                    if captured:
                        break
                    try:
                        elements = await page.query_selector_all(selector)
                        if elements:
                            # Get last response
                            text = await elements[-1].inner_text()
                            if len(text) > 30:
                                responses.append({
                                    "iteration": i + 1,
                                    "content": text,
                                    "length": len(text),
                                    "hash": hashlib.md5(text.encode()).hexdigest(),
                                })
                                print(f" âœ“ {len(text)} chars")
                                captured = True
                                break
                    except:
                        continue

                if not captured:
                    errors.append(f"Message {i+1}: No response captured")
                    print(" âœ— No response captured")

            except Exception as e:
                errors.append(f"Message {i+1}: {str(e)}")
                print(f"    âœ— Error: {e}")

            await context.close()

    # Calculate similarities
    if len(responses) >= 2:
        similarities = []
        for i in range(len(responses) - 1):
            sim = calculate_similarity(responses[i]["content"], responses[i+1]["content"])
            similarities.append(sim)
            print(f"  Response {i+1} vs {i+2}: {sim['overall']*100:.1f}%")

        avg_sim = {
            "length": sum(s["length_similarity"] for s in similarities) / len(similarities),
            "jaccard": sum(s["jaccard_similarity"] for s in similarities) / len(similarities),
            "character": sum(s["character_match"] for s in similarities) / len(similarities),
            "hash": sum(s["hash_match"] for s in similarities) / len(similarities),
            "overall": sum(s["overall"] for s in similarities) / len(similarities),
        }

        return {
            "provider": "gemini",
            "responses": responses,
            "errors": errors,
            "similarities": similarities,
            "avg_similarity": avg_sim,
        }

    return None


async def test_perplexity():
    """Test Perplexity reproducibility (3 iterations)."""
    profile_path = PROFILE_DIR / "perplexity"

    if not profile_path.exists():
        print("Perplexity profile not found")
        return None

    responses = []
    errors = []

    print("\n" + "="*60)
    print("Testing PERPLEXITY")
    print("="*60)

    async with async_playwright() as p:
        for i in range(3):
            context = await p.chromium.launch_persistent_context(
                str(profile_path),
                headless=False,
                channel=BROWSER_CHANNEL,
                viewport={"width": 1280, "height": 800"},
                args=["--disable-blink-features=AutomationControlled"],
            )
            page = context.pages[0] if context.pages else await context.new_page()

            try:
                await page.goto("https://www.perplexity.ai", wait_until="domcontentloaded", timeout=30000)

                # Check login
                if "login" in page.url.lower():
                    print(f"  Message {i+1}/3: âœ— Not logged in")
                    await context.close()
                    return None

                print(f"  Message {i+1}/3...")

                # Wait for input
                await page.wait_for_selector("[role='textbox'], textarea", timeout=15000)

                # Get the input element
                textbox = await page.query_selector("[role='textbox'], textarea")
                if not textbox:
                    errors.append(f"Message {i+1}: No textbox found")
                    print(f"    âœ— No textbox found")
                    await context.close()
                    continue

                # Type message
                await textbox.fill(PROMPT)
                await asyncio.sleep(1)

                # Submit
                await textbox.press("Enter")
                print("    sent, waiting...", end="", flush=True)

                # Wait for response
                await asyncio.sleep(20)

                # Capture response - try multiple selectors
                captured = False
                selectors = [
                    "div.thread-message",
                    "div[class*='answer']",
                    "div[class*='prose']",
                ]

                for selector in selectors:
                    if captured:
                        break
                    try:
                        elements = await page.query_selector_all(selector)
                        if elements:
                            # Get last response
                            text = await elements[-1].inner_text()
                            if len(text) > 30:
                                responses.append({
                                    "iteration": i + 1,
                                    "content": text,
                                    "length": len(text),
                                    "hash": hashlib.md5(text.encode()).hexdigest(),
                                })
                                print(f" âœ“ {len(text)} chars")
                                captured = True
                                break
                    except:
                        continue

                if not captured:
                    errors.append(f"Message {i+1}: No response captured")
                    print(" âœ— No response captured")

            except Exception as e:
                errors.append(f"Message {i+1}: {str(e)}")
                print(f"    âœ— Error: {e}")

            await context.close()

    # Calculate similarities
    if len(responses) >= 2:
        similarities = []
        for i in range(len(responses) - 1):
            sim = calculate_similarity(responses[i]["content"], responses[i+1]["content"])
            similarities.append(sim)
            print(f"  Response {i+1} vs {i+2}: {sim['overall']*100:.1f}%")

        avg_sim = {
            "length": sum(s["length_similarity"] for s in similarities) / len(similarities),
            "jaccard": sum(s["jaccard_similarity"] for s in similarities) / len(similarities),
            "character": sum(s["character_match"] for s in similarities) / len(similarities),
            "hash": sum(s["hash_match"] for s in similarities) / len(similarities),
            "overall": sum(s["overall"] for s in similarities) / len(similarities),
        }

        return {
            "provider": "perplexity",
            "responses": responses,
            "errors": errors,
            "similarities": similarities,
            "avg_similarity": avg_sim,
        }

    return None


def generate_report(results: list) -> str:
    """Generate test report."""
    lines = []
    lines.append("# Gemini & Perplexity ì¬í˜„ì„± í‰ê°€ ë³´ê³ ì„œ")
    lines.append("")
    lines.append(f"**í‰ê°€ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append(f"**í‰ê°€ ë°©ì‹**: Playwright ì›¹ ë¸Œë¼ìš°ì € ì ‘ì†")
    lines.append(f"**ë°˜ë³µ íšŸìˆ˜**: 3íšŒ")
    lines.append(f"**ì°¸ê³ **: ClaudeëŠ” ì¸ì¦ ë¬¸ì œë¡œ ì œì™¸")
    lines.append("")

    # Summary
    lines.append("## 1. í‰ê°€ ê°œìš”")
    lines.append("")
    lines.append("| AI | ìƒíƒœ | ì„±ê³µ | í‰ê·  ìœ ì‚¬ë„ |")
    lines.append("|----|------|------|-----------|")

    for r in results:
        if r and "avg_similarity" in r:
            status = "âœ… ì™„ë£Œ"
            success = f"{len(r['responses'])}/3"
            avg_sim = f"{r['avg_similarity']['overall']*100:.1f}%"
        elif r and r.get("responses"):
            status = "âš ï¸ ë¶€ë¶„ ì™„ë£Œ"
            success = f"{len(r['responses'])}/3"
            avg_sim = "N/A (ì‘ë‹µ < 2)"
        else:
            status = "âŒ ì‹¤íŒ¨"
            success = "0/3"
            avg_sim = "N/A"

        lines.append(f"| {r['provider']} | {status} | {success} | {avg_sim} |")

    lines.append("")

    # Detailed results
    lines.append("## 2. ìƒì„¸ ê²°ê³¼")
    lines.append("")

    for r in results:
        if r:
            lines.append(f"### {r['provider'].upper()}")
            lines.append("")
            lines.append(f"- **ìƒíƒœ**: {'ì™„ë£Œ' if len(r.get('responses', [])) >= 2 else 'ë¶€ë¶„ ì™„ë£Œ' if r.get('responses') else 'ì‹¤íŒ¨'}")

            if r.get("errors"):
                lines.append(f"- **ì˜¤ë¥˜**: {', '.join(r['errors'][:3])}")  # First 3 errors

            if r.get("responses"):
                lines.append("")
                lines.append("**ì‘ë‹µ ìš”ì•½**:")
                for resp in r["responses"]:
                    preview = resp["content"][:100].replace("\n", " ")
                    lines.append(f"  - ë°˜ë³µ {resp['iteration']}: {resp['length']}ì, í•´ì‹œ={resp['hash'][:12]}...")
                    lines.append(f"    ë‚´ìš©: {preview}...")

            if "avg_similarity" in r:
                avg = r["avg_similarity"]
                lines.append("")
                lines.append("**ìœ ì‚¬ë„ ë¶„ì„**:")
                lines.append(f"- ê¸¸ì´ ìœ ì‚¬ë„: {avg['length']*100:.1f}%")
                lines.append(f"- ë‹¨ì–´ ì¤‘ì²©ë„: {avg['jaccard']*100:.1f}%")
                lines.append(f"- ë¬¸ì ì¼ì¹˜: {avg['character']*100:.1f}%")
                lines.append(f"- í•´ì‹œ ì¼ì¹˜: {avg['hash']*100:.1f}%")
                lines.append(f"- **ì¢…í•© ìœ ì‚¬ë„: {avg['overall']*100:.1f}%**")

            lines.append("")

    # Overall assessment
    lines.append("## 3. ì¢…í•© í‰ê°€")
    lines.append("")

    completed = [r for r in results if r and "avg_similarity" in r]

    if completed:
        overall_sim = sum(r["avg_similarity"]["overall"] for r in completed) / len(completed)
        lines.append(f"- **í‰ê°€ ì™„ë£Œ**: {len(completed)}/{len(results)}ê°œ AI")
        lines.append(f"- **í‰ê·  ìœ ì‚¬ë„**: {overall_sim*100:.1f}%")

        if overall_sim >= 0.9:
            grade = "A+"
            assessment = "ë§¤ìš° ìš°ìˆ˜í•œ ì¬í˜„ì„±"
        elif overall_sim >= 0.8:
            grade = "A"
            assessment = "ìš°ìˆ˜í•œ ì¬í˜„ì„±"
        elif overall_sim >= 0.7:
            grade = "B"
            assessment = "ì–‘í˜¸í•œ ì¬í˜„ì„±"
        elif overall_sim >= 0.5:
            grade = "C"
            assessment = "ë³´í†µ ìˆ˜ì¤€"
        else:
            grade = "D"
            assessment = "ê°œì„  í•„ìš”"

        lines.append(f"- **í’ˆì§ˆ ë“±ê¸‰**: {grade} ({assessment})")

    lines.append("")
    lines.append("**ì°¸ê³ **:")
    lines.append("- Claude.aiëŠ” ì¸ì¦ í™•ì¸ ì°½ ë¬´í•œ ë°˜ë³µ ë¬¸ì œë¡œ ì œì™¸")
    lines.append("- Claude ì¸ì¦ í•´ê²° í›„ ë³„ë„ í‰ê°€ í•„ìš”")
    lines.append("")
    lines.append("*ë³´ê³ ì„œ ìƒì„±ì¼: " + datetime.now().strftime('%Y-%m-%d %H:%M'))

    return "\\n".join(lines)


async def main():
    """Main function."""
    print("\n" + "="*60)
    print("GEMINI & PERPLEXITY REPRODUCIBILITY TEST")
    print("="*60)
    print("\\nClaude excluded due to auth issue")
    print("Testing Gemini and Perplexity...\\n")

    results = []

    # Test Gemini
    gemini_result = await test_gemini()
    if gemini_result:
        results.append(gemini_result)

    # Test Perplexity
    perplexity_result = await test_perplexity()
    if perplexity_result:
        results.append(perplexity_result)

    # Generate report
    if results:
        report = generate_report(results)
        report_path = Path("docs/ai-reproducibility-results/actual/gemini-perplexity-reproducibility.md")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        report_path.write_text(report, encoding="utf-8")

        print(f"\n{'='*60}")
        print(f"ğŸ“„ ë³´ê³ ì„œ: {report_path}")
        print(f"{'='*60}")
    else:
        print("\\nNo successful tests completed.")


if __name__ == "__main__":
    asyncio.run(main())
